# ğŸŒ± NDVI-based Land Cover Classification | Summer Analytics 2025 Hackathon

Welcome to my submission for the **First Course Hackathon - Summer Analytics 2025**, hosted by the **Consulting & Analytics Club** in collaboration with **GeeksforGeeks**.

## ğŸš€ Overview

The goal of this hackathon was to build a **Multiclass Logistic Regression** model that classifies land cover types using **NDVI (Normalized Difference Vegetation Index)** time-series data. Each sample represents a location with 27 NDVI observations across time, alongside a labeled land cover type from six categories:

- **Water**
- **Impervious**
- **Farm**
- **Forest**
- **Grass**
- **Orchard**

### ğŸ¯ Objective

Design a model that performs well even under **noisy** and **incomplete** data conditions â€” simulating real-world remote sensing challenges like cloud interference and imperfect labeling.

---

## ğŸ“š What I Learned

### ğŸŒ Domain Knowledge
- Understood the significance of **NDVI** in analyzing vegetation health.
- Learned how land cover classification supports ecological monitoring and urban planning.

### ğŸ“ˆ Machine Learning Skills
- Implemented **Multiclass Logistic Regression** from scratch and using `scikit-learn`.
- Tackled **imbalanced classes** using class weights and stratified sampling.

### ğŸ§¹ Data Preprocessing & Feature Engineering
- **Imputation Techniques**: Used forward fill and mean strategies to handle missing NDVI values due to cloud cover.
- **Denoising**: Applied smoothing techniques like rolling averages to reduce the effect of noisy NDVI time points.
- **Feature Extraction**: Generated statistical summaries (mean, std, min, max, trend) to capture vegetation dynamics over time.

### ğŸ§ª Evaluation
- Split the data strategically to mimic public/private leaderboard settings.
- Validated generalization using clean test data to avoid overfitting noisy training data.

---

## âš™ï¸ Project Structure

```bash
.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA_and_Preprocessing.ipynb
â”‚   â””â”€â”€ Logistic_Regression_Model.ipynb
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ sample_submission.csv
â”œâ”€â”€ submission/
â”‚   â””â”€â”€ final_submission.csv
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


ğŸ“Š Results
Achieved competitive accuracy on both public and private leaderboards using only logistic regression.

Learned how important robust preprocessing and feature engineering are when working with real-world noisy datasets.

ğŸ§  Key Takeaways
Logistic Regression, though simple, can be powerful with the right features.

Time-series data needs careful transformation for use in traditional ML models.

Understanding the data generation process (e.g., NDVI behavior) boosts modeling decisions.

ğŸ“¥ Submission Format
csv
Copy
Edit
ID,class
1,water
2,forest
3,grass
...
ğŸ›  Tech Stack
Python (Pandas, NumPy, Scikit-learn, Matplotlib)

Jupyter Notebook

Logistic Regression (Multinomial)

ğŸ Final Thoughts
This project helped bridge satellite remote sensing with applied machine learning. Handling missing values, denoising time-series, and working with logistic regression under constraints simulated real-world constraints beautifully.

ğŸ”— Thanks to CAC and GFG for the opportunity!
